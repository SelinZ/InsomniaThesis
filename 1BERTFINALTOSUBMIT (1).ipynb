{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1A2XyzJfR0NKBWtbJdHJCNuIWRl2NeokT","timestamp":1687363343813}],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"193584044e4d46e5962d2228522adeb4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b8b93ef2710340c4ac1199d2e0d32980","IPY_MODEL_3515536bc0a04f249047ebf32ae3d285","IPY_MODEL_f9b75a475d404d0693e80dd67127357d"],"layout":"IPY_MODEL_44e93f69ee42420aa4ed446e22fe7e5e"}},"b8b93ef2710340c4ac1199d2e0d32980":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1dfb0e310ae4beb9d5265cc5d59e849","placeholder":"​","style":"IPY_MODEL_9a06dc3af68f46e4a76de4ab35cadce5","value":"Downloading (…)lve/main/config.json: 100%"}},"3515536bc0a04f249047ebf32ae3d285":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62d150641d14484bbd0431c7d1fc5c70","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b821814c322444097f9d7dc755f86d5","value":570}},"f9b75a475d404d0693e80dd67127357d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a984b9a08e745a0bbfe3762d6d2f373","placeholder":"​","style":"IPY_MODEL_bbb8dba578f64a96a57512e1a237b361","value":" 570/570 [00:00&lt;00:00, 23.8kB/s]"}},"44e93f69ee42420aa4ed446e22fe7e5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1dfb0e310ae4beb9d5265cc5d59e849":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a06dc3af68f46e4a76de4ab35cadce5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62d150641d14484bbd0431c7d1fc5c70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b821814c322444097f9d7dc755f86d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a984b9a08e745a0bbfe3762d6d2f373":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbb8dba578f64a96a57512e1a237b361":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc0752d5008f436b8394c3ee02ace60a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_061fc4ebe684461cb64b38e8731cbeb4","IPY_MODEL_e570f9012a174d3fbfa2afb7526f3fe6","IPY_MODEL_13ac308416494654bd495876d04c548b"],"layout":"IPY_MODEL_15a7e2d222234c7ba1322c14ee3799df"}},"061fc4ebe684461cb64b38e8731cbeb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53ed7a42604547418bd59f8372cabaa1","placeholder":"​","style":"IPY_MODEL_98daf20adbb74ab7a600c5b0bda15a7d","value":"Downloading model.safetensors: 100%"}},"e570f9012a174d3fbfa2afb7526f3fe6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7965bd5db94d439d9dacf5ccd6dc28f2","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68f077cbd42c4dac8b8179d01f3ac144","value":440449768}},"13ac308416494654bd495876d04c548b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf66ac47e7a343ed9b0e58b99f52ad69","placeholder":"​","style":"IPY_MODEL_22c0dbcf746b49cd8765d86c21345133","value":" 440M/440M [00:03&lt;00:00, 134MB/s]"}},"15a7e2d222234c7ba1322c14ee3799df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53ed7a42604547418bd59f8372cabaa1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98daf20adbb74ab7a600c5b0bda15a7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7965bd5db94d439d9dacf5ccd6dc28f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68f077cbd42c4dac8b8179d01f3ac144":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf66ac47e7a343ed9b0e58b99f52ad69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22c0dbcf746b49cd8765d86c21345133":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1d21f233789435fb51a6a974613de09":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39a2a04a8d764b7a94af478c261acfcd","IPY_MODEL_40603ec306a54879bc51b0d11c3d2830","IPY_MODEL_bf7f9750414644c1b85b80420f2f44f6"],"layout":"IPY_MODEL_c3fce04a0eb14264bdf253f85731b01c"}},"39a2a04a8d764b7a94af478c261acfcd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f40825383eb4fd3887c354db909301c","placeholder":"​","style":"IPY_MODEL_2bb31a02aaaa499b8824d6b98462fc3e","value":"Downloading (…)okenizer_config.json: 100%"}},"40603ec306a54879bc51b0d11c3d2830":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_916273af20ca4238bdd7e741100af1ad","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79e401d375924aa1923520527e3eb927","value":28}},"bf7f9750414644c1b85b80420f2f44f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6e60294ded44922b2ae7fd9b5ec0a8f","placeholder":"​","style":"IPY_MODEL_a2b9ece1f6984f99b5f1815f94991cfd","value":" 28.0/28.0 [00:00&lt;00:00, 1.66kB/s]"}},"c3fce04a0eb14264bdf253f85731b01c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f40825383eb4fd3887c354db909301c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bb31a02aaaa499b8824d6b98462fc3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"916273af20ca4238bdd7e741100af1ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79e401d375924aa1923520527e3eb927":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a6e60294ded44922b2ae7fd9b5ec0a8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2b9ece1f6984f99b5f1815f94991cfd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b428b4a2ed346a98ad369e5afbf6d0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ba620e1375a4e7c8cc9545c05e1b034","IPY_MODEL_4fffe3cb975f4334b9a186a2b71f3939","IPY_MODEL_590d65f5597b45faa10a238292f2f6de"],"layout":"IPY_MODEL_6b1c3cb4b5b74a78a70c4f84eddf45c2"}},"5ba620e1375a4e7c8cc9545c05e1b034":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c38cbb23fbcd43ff812f5b729a8d61e2","placeholder":"​","style":"IPY_MODEL_f46b72d848d34419b130ec3f722ee495","value":"Downloading (…)solve/main/vocab.txt: "}},"4fffe3cb975f4334b9a186a2b71f3939":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98f92b585a964575a4401d2d25cc5d90","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0943ad676fd1464b97d834af2f22f89d","value":1}},"590d65f5597b45faa10a238292f2f6de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_389d9da27b5a492cbb99ae5a66cb5867","placeholder":"​","style":"IPY_MODEL_2f08a88984a24d88b7eecb1d13732e7c","value":" 232k/? [00:00&lt;00:00, 4.09MB/s]"}},"6b1c3cb4b5b74a78a70c4f84eddf45c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c38cbb23fbcd43ff812f5b729a8d61e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f46b72d848d34419b130ec3f722ee495":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98f92b585a964575a4401d2d25cc5d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"0943ad676fd1464b97d834af2f22f89d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"389d9da27b5a492cbb99ae5a66cb5867":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f08a88984a24d88b7eecb1d13732e7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5196c0610fe9456d8b52f96f1703f2b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98959212ef5e4d6393ac733708f7e6d2","IPY_MODEL_8feca58738f04d4ba506f125ab3abe94","IPY_MODEL_59591518de124f10b5b7e637dc5ad998"],"layout":"IPY_MODEL_933c5ac655104f75923a586ae0f9d1c9"}},"98959212ef5e4d6393ac733708f7e6d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27fc7a5d02a4492389868ff651c6cbe3","placeholder":"​","style":"IPY_MODEL_a26424ca589b4d12be699fb2ce89afc2","value":"Downloading (…)/main/tokenizer.json: "}},"8feca58738f04d4ba506f125ab3abe94":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ff45d75179240b68c0349f36909ddf4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c00fac1e7dd64549a0edb1c02d3c7ce4","value":1}},"59591518de124f10b5b7e637dc5ad998":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d4c48208eb643e2b1cd2b2862758079","placeholder":"​","style":"IPY_MODEL_38fd9b0f69ae4386b2fffbe4baef7aaf","value":" 466k/? [00:00&lt;00:00, 8.10MB/s]"}},"933c5ac655104f75923a586ae0f9d1c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27fc7a5d02a4492389868ff651c6cbe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a26424ca589b4d12be699fb2ce89afc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ff45d75179240b68c0349f36909ddf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c00fac1e7dd64549a0edb1c02d3c7ce4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d4c48208eb643e2b1cd2b2862758079":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38fd9b0f69ae4386b2fffbe4baef7aaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"TpJA9khxhMN8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5fa3409-141f-4d96-923f-1e1168edc7f7","executionInfo":{"status":"ok","timestamp":1687525519275,"user_tz":-120,"elapsed":20376,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"]}],"source":["#https://www.kaggle.com/code/harshjain123/bert-for-everyone-tutorial-implementation\n","#https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/\n","\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","!pip install transformers\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","\n","# specify GPU\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","source":["def set_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)"],"metadata":{"id":"C1Oyl7ORJYcE","executionInfo":{"status":"ok","timestamp":1687525519275,"user_tz":-120,"elapsed":3,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVbV-STDHmo_","outputId":"9dd263e6-f4a2-4a28-a989-98681950c41b","executionInfo":{"status":"ok","timestamp":1687525530551,"user_tz":-120,"elapsed":11278,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","source":["from pathlib import Path\n","print(Path.cwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24pd8jk8RhJp","outputId":"411c4b9e-eaa5-4b90-d81c-4132bf5ee175","executionInfo":{"status":"ok","timestamp":1687525530552,"user_tz":-120,"elapsed":5,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('Scombined.csv')\n","#df.drop(['score', 'length'], inplace = True, axis = 1)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"2GLDtZJ3B5vo","outputId":"41565360-62fc-4290-dc42-da594b174e0b","executionInfo":{"status":"ok","timestamp":1687525531285,"user_tz":-120,"elapsed":736,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                selftext  y  \\\n","0      I've used this app called 'Relax Melodies' for...  0   \n","1      I felt reasonably tired at my bed time. I got ...  0   \n","2      And to hear how they slept poorly the next day...  0   \n","3      Whenever it is warm outside, there is a bird t...  0   \n","4      I was on 20-25mg Mirtazapine (Remeron) over th...  0   \n","...                                                  ... ..   \n","18394  I’ve been at day 4, not many times, it’s where...  1   \n","18395  Hi, everyone I’m a new poster in this sub but ...  1   \n","18396  I have a very hard time falling asleep, I can ...  1   \n","18397  anyone else rly want to sleep and feel tired b...  1   \n","18398  I'm at it again fellas. Around this time last ...  1   \n","\n","                                                   clean  \\\n","0      I've used this app called 'Relax Melodies' for...   \n","1      I felt reasonably tired at my bed time. I got ...   \n","2      And to hear how they slept poorly the next day...   \n","3      Whenever it is warm outside, there is a bird t...   \n","4      I was on 20-25mg Mirtazapine (Remeron) over th...   \n","...                                                  ...   \n","18394  I’ve been at day 4, not many times, it’s where...   \n","18395  Hi, everyone I’m a new poster in this sub but ...   \n","18396  I have a very hard time falling asleep, I can ...   \n","18397  anyone else rly want to sleep and feel tired b...   \n","18398  I'm at it again fellas. Around this time last ...   \n","\n","                                                    text  length  \\\n","0      i ve used this app called relax melodies for o...     886   \n","1      i felt reasonably tired at my bed time i got i...     214   \n","2      and to hear how they slept poorly the next day...      61   \n","3      whenever it is warm outside there is a bird th...     255   \n","4      i was on      mg mirtazapine remeron over the ...     977   \n","...                                                  ...     ...   \n","18394  i ve been at day   not many times it s where i...     512   \n","18395  hi everyone i m a new poster in this sub but i...    1469   \n","18396  i have a very hard time falling asleep i can b...     183   \n","18397  anyone else rly want to sleep and feel tired b...     107   \n","18398  i m at it again fellas around this time last y...     494   \n","\n","                                                    rem2  \n","0      used app called relax melodies two years app i...  \n","1      felt reasonably tired bed time got bed closed ...  \n","2                      hear slept poorly next day luxury  \n","3      whenever warm outside bird chirps outside wind...  \n","4      mg mirtazapine remeron past years months ago b...  \n","...                                                  ...  \n","18394  day many times incredible moodiness overwhelmi...  \n","18395  hi everyone new poster sub trying see anyone e...  \n","18396  hard time falling asleep exhausted cant switch...  \n","18397  anyone else rly want sleep feel tired get anxi...  \n","18398  fellas around time last year first bout insomn...  \n","\n","[18399 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-eefdfcd3-b32b-4065-a469-67d7a5cb9b79\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>selftext</th>\n","      <th>y</th>\n","      <th>clean</th>\n","      <th>text</th>\n","      <th>length</th>\n","      <th>rem2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I've used this app called 'Relax Melodies' for...</td>\n","      <td>0</td>\n","      <td>I've used this app called 'Relax Melodies' for...</td>\n","      <td>i ve used this app called relax melodies for o...</td>\n","      <td>886</td>\n","      <td>used app called relax melodies two years app i...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I felt reasonably tired at my bed time. I got ...</td>\n","      <td>0</td>\n","      <td>I felt reasonably tired at my bed time. I got ...</td>\n","      <td>i felt reasonably tired at my bed time i got i...</td>\n","      <td>214</td>\n","      <td>felt reasonably tired bed time got bed closed ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>And to hear how they slept poorly the next day...</td>\n","      <td>0</td>\n","      <td>And to hear how they slept poorly the next day...</td>\n","      <td>and to hear how they slept poorly the next day...</td>\n","      <td>61</td>\n","      <td>hear slept poorly next day luxury</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Whenever it is warm outside, there is a bird t...</td>\n","      <td>0</td>\n","      <td>Whenever it is warm outside, there is a bird t...</td>\n","      <td>whenever it is warm outside there is a bird th...</td>\n","      <td>255</td>\n","      <td>whenever warm outside bird chirps outside wind...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I was on 20-25mg Mirtazapine (Remeron) over th...</td>\n","      <td>0</td>\n","      <td>I was on 20-25mg Mirtazapine (Remeron) over th...</td>\n","      <td>i was on      mg mirtazapine remeron over the ...</td>\n","      <td>977</td>\n","      <td>mg mirtazapine remeron past years months ago b...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>18394</th>\n","      <td>I’ve been at day 4, not many times, it’s where...</td>\n","      <td>1</td>\n","      <td>I’ve been at day 4, not many times, it’s where...</td>\n","      <td>i ve been at day   not many times it s where i...</td>\n","      <td>512</td>\n","      <td>day many times incredible moodiness overwhelmi...</td>\n","    </tr>\n","    <tr>\n","      <th>18395</th>\n","      <td>Hi, everyone I’m a new poster in this sub but ...</td>\n","      <td>1</td>\n","      <td>Hi, everyone I’m a new poster in this sub but ...</td>\n","      <td>hi everyone i m a new poster in this sub but i...</td>\n","      <td>1469</td>\n","      <td>hi everyone new poster sub trying see anyone e...</td>\n","    </tr>\n","    <tr>\n","      <th>18396</th>\n","      <td>I have a very hard time falling asleep, I can ...</td>\n","      <td>1</td>\n","      <td>I have a very hard time falling asleep, I can ...</td>\n","      <td>i have a very hard time falling asleep i can b...</td>\n","      <td>183</td>\n","      <td>hard time falling asleep exhausted cant switch...</td>\n","    </tr>\n","    <tr>\n","      <th>18397</th>\n","      <td>anyone else rly want to sleep and feel tired b...</td>\n","      <td>1</td>\n","      <td>anyone else rly want to sleep and feel tired b...</td>\n","      <td>anyone else rly want to sleep and feel tired b...</td>\n","      <td>107</td>\n","      <td>anyone else rly want sleep feel tired get anxi...</td>\n","    </tr>\n","    <tr>\n","      <th>18398</th>\n","      <td>I'm at it again fellas. Around this time last ...</td>\n","      <td>1</td>\n","      <td>I'm at it again fellas. Around this time last ...</td>\n","      <td>i m at it again fellas around this time last y...</td>\n","      <td>494</td>\n","      <td>fellas around time last year first bout insomn...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>18399 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eefdfcd3-b32b-4065-a469-67d7a5cb9b79')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-eefdfcd3-b32b-4065-a469-67d7a5cb9b79 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-eefdfcd3-b32b-4065-a469-67d7a5cb9b79');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["# New section"],"metadata":{"id":"9E-ybPuWkuFQ"}},{"cell_type":"code","source":["# check class distribution\n","df['y'].value_counts(normalize = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cMUxVRidB5yJ","outputId":"8bdf8088-3e68-46f9-d8d8-560ec06a0f9c","executionInfo":{"status":"ok","timestamp":1687389348578,"user_tz":-120,"elapsed":300,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0.529974\n","1    0.470026\n","Name: y, dtype: float64"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","print(df['selftext'][5])\n","print()\n","print(df['clean'][5])\n","\n","df_bert = df[['selftext', 'clean', 'y']]\n","df_bert.reset_index(inplace=True)\n","\n","train_text, temp_text, train_labels, temp_labels = train_test_split(df_bert['selftext'], df_bert['y'],\n","                                                                    random_state=20,\n","                                                                    test_size=0.4,\n","                                                                    stratify=df_bert['y'])\n","\n","\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n","                                                                random_state=20,\n","                                                                test_size=0.5,\n","                                                                stratify=temp_labels)"],"metadata":{"id":"-dVHzevkSnVl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687525531285,"user_tz":-120,"elapsed":2,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"7ac86f7a-f1b7-4bd2-dc5c-dd97cef10d1d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Dealing with insomnia while packing and moving to a new place is quite the rigorous test. Hypno-sleep 'til Brooklyn? http://touch.metro.us/news/the-insomniac-files-is-the-hypnotic-trance-my-last-chance/zsJqbB---5KiVhLU99Evgk/\n","\n","Dealing with insomnia while packing and moving to a new place is quite the rigorous test. Hypno-sleep 'til Brooklyn?\n"]}]},{"cell_type":"code","source":["# import BERT-base pretrained model\n","bert = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# Load the BERT tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248,"referenced_widgets":["193584044e4d46e5962d2228522adeb4","b8b93ef2710340c4ac1199d2e0d32980","3515536bc0a04f249047ebf32ae3d285","f9b75a475d404d0693e80dd67127357d","44e93f69ee42420aa4ed446e22fe7e5e","f1dfb0e310ae4beb9d5265cc5d59e849","9a06dc3af68f46e4a76de4ab35cadce5","62d150641d14484bbd0431c7d1fc5c70","0b821814c322444097f9d7dc755f86d5","8a984b9a08e745a0bbfe3762d6d2f373","bbb8dba578f64a96a57512e1a237b361","dc0752d5008f436b8394c3ee02ace60a","061fc4ebe684461cb64b38e8731cbeb4","e570f9012a174d3fbfa2afb7526f3fe6","13ac308416494654bd495876d04c548b","15a7e2d222234c7ba1322c14ee3799df","53ed7a42604547418bd59f8372cabaa1","98daf20adbb74ab7a600c5b0bda15a7d","7965bd5db94d439d9dacf5ccd6dc28f2","68f077cbd42c4dac8b8179d01f3ac144","cf66ac47e7a343ed9b0e58b99f52ad69","22c0dbcf746b49cd8765d86c21345133","c1d21f233789435fb51a6a974613de09","39a2a04a8d764b7a94af478c261acfcd","40603ec306a54879bc51b0d11c3d2830","bf7f9750414644c1b85b80420f2f44f6","c3fce04a0eb14264bdf253f85731b01c","1f40825383eb4fd3887c354db909301c","2bb31a02aaaa499b8824d6b98462fc3e","916273af20ca4238bdd7e741100af1ad","79e401d375924aa1923520527e3eb927","a6e60294ded44922b2ae7fd9b5ec0a8f","a2b9ece1f6984f99b5f1815f94991cfd","4b428b4a2ed346a98ad369e5afbf6d0c","5ba620e1375a4e7c8cc9545c05e1b034","4fffe3cb975f4334b9a186a2b71f3939","590d65f5597b45faa10a238292f2f6de","6b1c3cb4b5b74a78a70c4f84eddf45c2","c38cbb23fbcd43ff812f5b729a8d61e2","f46b72d848d34419b130ec3f722ee495","98f92b585a964575a4401d2d25cc5d90","0943ad676fd1464b97d834af2f22f89d","389d9da27b5a492cbb99ae5a66cb5867","2f08a88984a24d88b7eecb1d13732e7c","5196c0610fe9456d8b52f96f1703f2b9","98959212ef5e4d6393ac733708f7e6d2","8feca58738f04d4ba506f125ab3abe94","59591518de124f10b5b7e637dc5ad998","933c5ac655104f75923a586ae0f9d1c9","27fc7a5d02a4492389868ff651c6cbe3","a26424ca589b4d12be699fb2ce89afc2","7ff45d75179240b68c0349f36909ddf4","c00fac1e7dd64549a0edb1c02d3c7ce4","5d4c48208eb643e2b1cd2b2862758079","38fd9b0f69ae4386b2fffbe4baef7aaf"]},"id":"fcdhA0shSnYQ","outputId":"c0c5aff0-8fc7-47e6-b8f2-7d24e14cb575","executionInfo":{"status":"ok","timestamp":1687525537500,"user_tz":-120,"elapsed":6216,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"193584044e4d46e5962d2228522adeb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc0752d5008f436b8394c3ee02ace60a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1d21f233789435fb51a6a974613de09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b428b4a2ed346a98ad369e5afbf6d0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5196c0610fe9456d8b52f96f1703f2b9"}},"metadata":{}}]},{"cell_type":"code","source":["# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = 128,\n","    pad_to_max_length=True,\n","    truncation=True\n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = 128,\n","    pad_to_max_length=True,\n","    truncation=True\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = 128,\n","    pad_to_max_length=True,\n","    truncation=True\n",")"],"metadata":{"id":"6B7DVSQCSnde","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687525544378,"user_tz":-120,"elapsed":6880,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"328b8277-aa34-4537-b641-a693b4675738"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["## convert lists to tensors\n","\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"],"metadata":{"id":"4aCsnLUOB55c","executionInfo":{"status":"ok","timestamp":1687525545193,"user_tz":-120,"elapsed":817,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 32\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"metadata":{"id":"92iXwabBB57w","executionInfo":{"status":"ok","timestamp":1687525545193,"user_tz":-120,"elapsed":3,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["bert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l0XH94aE7Z9c","executionInfo":{"status":"ok","timestamp":1687384074842,"user_tz":-120,"elapsed":8,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"6f33acd0-54d7-4172-b7aa-e2cbf884cbe8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0-11): 12 x BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["train_seq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e8tVqfhQFEhY","outputId":"33f9f328-3917-4ae3-bf42-19f0ea251eff","executionInfo":{"status":"ok","timestamp":1687386264574,"user_tz":-120,"elapsed":219,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 101, 2750, 2108,  ..., 1010, 1996,  102],\n","        [ 101, 1020, 2420,  ...,    0,    0,    0],\n","        [ 101, 2061, 1010,  ..., 1006, 4983,  102],\n","        ...,\n","        [ 101, 1045, 4265,  ...,    0,    0,    0],\n","        [ 101, 1045, 1521,  ...,    0,    0,    0],\n","        [ 101, 1045, 4033,  ..., 2705, 2051,  102]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["'''# freeze all the parameters\n","for param in bert.parameters():\n","    param.requires_grad = False'''"],"metadata":{"id":"j7MM0PqrTPvE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","        super(BERT_Arch, self).__init__()\n","\n","        self.bert = bert\n","\n","        # dropout layer\n","        self.dropout = nn.Dropout(0.1)  #0.1\n","\n","        # relu activation function\n","       # self.relu =  nn.ReLU()\n","\n","        # dense layer 1\n","      #  self.fc1 = nn.Linear(768,512)\n","\n","        # dense layer 2 (Output layer)\n","        self.fc2 = nn.Linear(768,2)\n","\n","        #softmax activation function\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","        #pass the inputs to the model\n","        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n","\n","      #  x = self.fc1(cls_hs)\n","\n","#        x = self.relu(x)\n","\n","        x = self.dropout(cls_hs)\n","\n","        # output layer\n","        x = self.fc2(x)\n","\n","        # apply softmax activation\n","        x = self.softmax(x)\n","\n","        return x"],"metadata":{"id":"5GAcKMbjTPyM","executionInfo":{"status":"ok","timestamp":1687525545193,"user_tz":-120,"elapsed":2,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bert)\n","\n","# push the model to GPU\n","model = model.to(device)"],"metadata":{"id":"ykrY4ZnSTP2D","executionInfo":{"status":"ok","timestamp":1687525545194,"user_tz":-120,"elapsed":2,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(),lr = 2e-5)"],"metadata":{"id":"pL6yvrp-AcwU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687525545564,"user_tz":-120,"elapsed":6,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"58c1a7da-c24f-46e0-8202-e95463ac5889"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","#compute the class weights\n","class_weights = compute_class_weight(class_weight = \"balanced\", classes= np.unique(train_labels), y= train_labels)\n","\n","#class_weights = dict(zip(np.unique(train_labels), class_weights))\n","\n","print(\"Class Weights:\",class_weights)\n","\n","#Class Weights: [0.94350427 1.06369243]. random state 20'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iV3SwWen-sOb","executionInfo":{"status":"ok","timestamp":1687525545564,"user_tz":-120,"elapsed":5,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"d96f786b-96a9-4aa4-c005-348ed884680a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Class Weights: [0.94350427 1.06369243]\n"]}]},{"cell_type":"code","source":["# converting list of class weights to a tensor\n","weights= torch.tensor(class_weights,dtype=torch.float)\n","\n","# push to GPU\n","weights = weights.to(device)\n","\n","# define the loss function\n","cross_entropy  = nn.NLLLoss(weight=weights)\n","\n","# number of training epochs\n","epochs = 3      #10"],"metadata":{"id":"OFqTCbHsAc2z","executionInfo":{"status":"ok","timestamp":1687525545564,"user_tz":-120,"elapsed":2,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","def compute_metrics(pred, labels):\n","    #labels = pred.input_ids\n","    #preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, pred)\n","    acc = accuracy_score(labels, pred)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }"],"metadata":{"id":"8r6_OKeuQXzA","executionInfo":{"status":"ok","timestamp":1687525545564,"user_tz":-120,"elapsed":2,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["#FINE TUNE\n","\n","# function to train the model\n","def train():\n","\n","    model.train()\n","    total_loss, total_accuracy = 0, 0\n","\n","    # empty list to save model predictions\n","    total_preds=[]\n","\n","    # iterate over batches\n","    for step,batch in enumerate(train_dataloader):\n","\n","        # progress update after every 50 batches.\n","        if step % 50 == 0 and not step == 0:\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","        # push the batch to gpu\n","        batch = [r.to(device) for r in batch]\n","\n","        sent_id, mask, labels = batch\n","\n","        # clear previously calculated gradients\n","        model.zero_grad()\n","\n","        # get model predictions for the current batch\n","        preds = model(sent_id, mask)\n","\n","        # compute the loss between actual and predicted values\n","        loss = cross_entropy(preds, labels)\n","     #   metrics = compute_metrics(preds, labels)\n","\n","        # add on to the total loss\n","        total_loss = total_loss + loss.item()\n","\n","        # backward pass to calculate the gradients\n","        loss.backward()\n","\n","        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # update parameters\n","        optimizer.step()\n","\n","        # model predictions are stored on GPU. So, push it to CPU\n","        preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","    # compute the training loss of the epoch\n","    avg_loss = total_loss / len(train_dataloader)\n","\n","      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","      # reshape the predictions in form of (number of samples, no. of classes)\n","    total_preds  = np.concatenate(total_preds, axis=0)\n","\n","    #returns the loss and predictions\n","    return avg_loss, total_preds"],"metadata":{"id":"5bveiut7Atm7","executionInfo":{"status":"ok","timestamp":1687525545565,"user_tz":-120,"elapsed":3,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# get predictions for val data\n","with torch.no_grad():\n","    valpreds = model(val_seq.to(device), val_mask.to(device))\n","    valpreds = valpreds.detach().cpu().numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"4HnFeMApdD1e","executionInfo":{"status":"error","timestamp":1687525599556,"user_tz":-120,"elapsed":4251,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"23f40dce-4cc7-451b-ef75-144eb2ed268f"},"execution_count":18,"outputs":[{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-6314364f6c96>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get predictions for val data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvalpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-1d3a0659b924>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;31m#  x = self.fc1(cls_hs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_probs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.35 GiB (GPU 0; 14.75 GiB total capacity; 12.55 GiB already allocated; 1.11 GiB free; 12.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["import datetime\n","import time\n","#https://python-utils.readthedocs.io/en/latest/_modules/python_utils/time.html\n","\n","def format_time(timestamp, precision=datetime.timedelta(seconds=1)):\n","    '''Formats timedelta/datetime/seconds\n","\n","    >>> format_time('1')\n","    '0:00:01'\n","    >>> format_time(1.234)\n","    '0:00:01'\n","    >>> format_time(1)\n","    '0:00:01'\n","    >>> format_time(datetime.datetime(2000, 1, 2, 3, 4, 5, 6))\n","    '2000-01-02 03:04:05'\n","    >>> format_time(datetime.date(2000, 1, 2))\n","    '2000-01-02'\n","    >>> format_time(datetime.timedelta(seconds=3661))\n","    '1:01:01'\n","    >>> format_time(None)\n","    '--:--:--'\n","    >>> format_time(format_time)  # doctest: +ELLIPSIS\n","    Traceback (most recent call last):\n","        ...\n","    TypeError: Unknown type ...\n","\n","    '''\n","    precision_seconds = precision.total_seconds()\n","\n","    if isinstance(timestamp, six.string_types + six.integer_types + (float, )):\n","        try:\n","            castfunc = six.integer_types[-1]\n","            timestamp = datetime.timedelta(seconds=castfunc(timestamp))\n","        except OverflowError:  # pragma: no cover\n","            timestamp = None\n","\n","    if isinstance(timestamp, datetime.timedelta):\n","        seconds = timestamp.total_seconds()\n","        # Truncate the number to the given precision\n","        seconds = seconds - (seconds % precision_seconds)\n","\n","        return str(datetime.timedelta(seconds=seconds))\n","    elif isinstance(timestamp, datetime.datetime):  # pragma: no cover\n","        # Python 2 doesn't have the timestamp method\n","        if hasattr(timestamp, 'timestamp'):\n","            seconds = timestamp.timestamp()\n","        else:\n","            seconds = timedelta_to_seconds(timestamp - epoch)\n","\n","        # Truncate the number to the given precision\n","        seconds = seconds - (seconds % precision_seconds)\n","\n","        try:  # pragma: no cover\n","            if six.PY3:\n","                dt = datetime.datetime.fromtimestamp(seconds)\n","            else:\n","                dt = datetime.datetime.utcfromtimestamp(seconds)\n","        except ValueError:  # pragma: no cover\n","            dt = datetime.datetime.max\n","        return str(dt)\n","    elif isinstance(timestamp, datetime.date):\n","        return str(timestamp)\n","    elif timestamp is None:\n","        return '--:--:--'\n","    else:\n","        raise TypeError('Unknown type %s: %r' % (type(timestamp), timestamp))"],"metadata":{"id":"DyFl96j1UmMh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function for evaluating the model\n","def evaluate():\n","\n","    print(\"\\nEvaluating...\")\n","\n","    # deactivate dropout layers\n","    model.eval()\n","\n","    total_loss, total_accuracy = 0, 0\n","\n","    # empty list to save the model predictions\n","    total_preds = []\n","\n","    # iterate over batches\n","    for step,batch in enumerate(val_dataloader):\n","\n","        # Progress update every 50 batches.\n","        if step % 50 == 0 and not step == 0:\n","\n","            # Calculate elapsed time in minutes.\n","           # elapsed = format_time(time.time() - t0)\n","\n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","        # push the batch to gpu\n","        batch = [t.to(device) for t in batch]\n","        sent_id, mask, labels = batch\n","\n","        b_labels = batch[2].to(device)\n","\n","        # deactivate autograd\n","        with torch.no_grad():\n","\n","            # model predictions\n","            preds = model(sent_id, mask)\n","\n","            # compute the validation loss between actual and predicted values\n","            loss = cross_entropy(preds,labels)\n","\n","            total_loss = total_loss + loss.item()\n","\n","            preds = preds.detach().cpu().numpy()\n","\n","            total_preds.append(preds)\n","\n","            label_ids = b_labels.to('cpu').numpy()\n","\n","    # compute the validation loss of the epoch\n","    avg_loss = total_loss / len(val_dataloader)\n","\n","    # reshape the predictions in form of (number of samples, no. of classes)\n","    total_preds  = np.concatenate(total_preds, axis=0)\n","\n","    return avg_loss, total_preds, label_ids"],"metadata":{"id":"MTakwxmjAt3l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qXsOaNomesGT","executionInfo":{"status":"ok","timestamp":1687460447549,"user_tz":-120,"elapsed":425,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"5faba523-c806-4c29-dbd7-21339a5c92b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","fc2.weight                                                  (2, 768)\n","fc2.bias                                                        (2,)\n"]}]},{"cell_type":"code","source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","train_pred = []\n","val_pred = []\n","label_ids = []\n","\n","#for each epoch\n","for epoch in range(epochs):\n","\n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","\n","    #train model\n","    train_loss, train_pred = train()\n","\n","    #evaluate model\n","    valid_loss, val_pred, label_ids  = evaluate()\n","\n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","\n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","\n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"metadata":{"id":"X3I2L355AuIb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f52c37e0-a32a-4f29-ce95-2e2e115b61d8","executionInfo":{"status":"ok","timestamp":1687464001453,"user_tz":-120,"elapsed":718179,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Epoch 1 / 3\n","  Batch    50  of    345.\n","  Batch   100  of    345.\n","  Batch   150  of    345.\n","  Batch   200  of    345.\n","  Batch   250  of    345.\n","  Batch   300  of    345.\n","\n","Evaluating...\n","  Batch    50  of    115.\n","  Batch   100  of    115.\n","\n","Training Loss: 0.052\n","Validation Loss: 3.057\n","\n"," Epoch 2 / 3\n","  Batch    50  of    345.\n","  Batch   100  of    345.\n","  Batch   150  of    345.\n","  Batch   200  of    345.\n","  Batch   250  of    345.\n","  Batch   300  of    345.\n","\n","Evaluating...\n","  Batch    50  of    115.\n","  Batch   100  of    115.\n","\n","Training Loss: 0.049\n","Validation Loss: 2.255\n","\n"," Epoch 3 / 3\n","  Batch    50  of    345.\n","  Batch   100  of    345.\n","  Batch   150  of    345.\n","  Batch   200  of    345.\n","  Batch   250  of    345.\n","  Batch   300  of    345.\n","\n","Evaluating...\n","  Batch    50  of    115.\n","  Batch   100  of    115.\n","\n","Training Loss: 0.036\n","Validation Loss: 2.982\n"]}]},{"cell_type":"code","source":["evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9yPgc9Dkn9qC","executionInfo":{"status":"ok","timestamp":1687462891959,"user_tz":-120,"elapsed":23703,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"abafc64d-b95c-470b-c321-6262756521ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Evaluating...\n","  Batch    50  of    115.\n","  Batch   100  of    115.\n"]},{"output_type":"execute_result","data":{"text/plain":["(3.007325177607329,\n"," array([[-5.3137969e-03, -5.2400999e+00],\n","        [-6.5388752e-04, -7.3329000e+00],\n","        [-5.7167263e+00, -3.2959445e-03],\n","        ...,\n","        [-9.2642294e-04, -6.9846120e+00],\n","        [-7.3787829e-05, -9.5142756e+00],\n","        [-9.3932511e-05, -9.2731152e+00]], dtype=float32),\n"," tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n","         0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0'))"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["val_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WdRiugSMn9tD","executionInfo":{"status":"ok","timestamp":1687462932158,"user_tz":-120,"elapsed":495,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"10d02330-fb13-486c-f9ee-6e6fd4e714ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-5.3137969e-03, -5.2400999e+00],\n","       [-6.5388752e-04, -7.3329000e+00],\n","       [-5.7167263e+00, -3.2959445e-03],\n","       ...,\n","       [-9.2642294e-04, -6.9846120e+00],\n","       [-7.3787829e-05, -9.5142756e+00],\n","       [-9.3932511e-05, -9.2731152e+00]], dtype=float32)"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["len(labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQSooxhwoyyL","executionInfo":{"status":"ok","timestamp":1687463090473,"user_tz":-120,"elapsed":438,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"b8bf49bd-8856-4bd4-f05b-63e8692ee187"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["labelsl = [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n","        0, 1, 1, 0, 0, 1, 1, 1]"],"metadata":{"id":"szEts5UqoUtL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds)\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }"],"metadata":{"id":"O2eXiORloeCW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"],"metadata":{"id":"UVozpYxVAuZC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e66f2fcb-daaa-43e0-fa90-a24ceb04899d","executionInfo":{"status":"ok","timestamp":1687455180905,"user_tz":-120,"elapsed":803,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["#MAKE PREDICTIONS\n","\n","# get predictions for test data\n","with torch.no_grad():\n","    preds = model(test_seq.to(device), test_mask.to(device))\n","    preds = preds.detach().cpu().numpy()"],"metadata":{"id":"2lLiPln0Ac5L","colab":{"base_uri":"https://localhost:8080/","height":409},"executionInfo":{"status":"error","timestamp":1687455187969,"user_tz":-120,"elapsed":1748,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"1214a7b8-eef7-441b-ba0e-f0c8d628e425"},"execution_count":null,"outputs":[{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-c95fabd8f236>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# get predictions for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-1d3a0659b924>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;31m#  x = self.fc1(cls_hs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         )\n\u001b[0;32m-> 1020\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 425\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    426\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_probs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.35 GiB (GPU 0; 14.75 GiB total capacity; 12.50 GiB already allocated; 1.02 GiB free; 12.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["# model's performance\n","preds = np.argmax(preds, axis = 1)\n","print(classification_report(test_y, preds))\n","\n","'''       precision    recall  f1-score   support\n","\n","           0       0.61      0.65      0.63      1951\n","           1       0.57      0.53      0.55      1729\n","\n","    accuracy                           0.59      3680\n","   macro avg       0.59      0.59      0.59      3680\n","weighted avg       0.59      0.59      0.59      3680\n","\n","weights\n","\n"," precision    recall  f1-score   support\n","\n","           0       0.60      0.65      0.63      1951\n","           1       0.57      0.52      0.54      1729\n","\n","    accuracy                           0.59      3680\n","   macro avg       0.59      0.59      0.59      3680\n","weighted avg       0.59      0.59      0.59      3680\n","\n","'''"],"metadata":{"id":"33qatWLLAc7Z","colab":{"base_uri":"https://localhost:8080/","height":224},"outputId":"877ff4f6-8a3a-4e08-a07b-6d18bb89a419","executionInfo":{"status":"ok","timestamp":1687389623497,"user_tz":-120,"elapsed":270,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.60      0.65      0.63      1951\n","           1       0.57      0.52      0.54      1729\n","\n","    accuracy                           0.59      3680\n","   macro avg       0.59      0.59      0.59      3680\n","weighted avg       0.59      0.59      0.59      3680\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["'       precision    recall  f1-score   support\\n\\n           0       0.61      0.65      0.63      1951\\n           1       0.57      0.53      0.55      1729\\n\\n    accuracy                           0.59      3680\\n   macro avg       0.59      0.59      0.59      3680\\nweighted avg       0.59      0.59      0.59      3680'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["predicted = preds\n","y_test = test_y\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(8,8))\n","\n","print(\" Accuracy:\",metrics.accuracy_score(y_test, predicted))\n","print(\"Precision:\",metrics.precision_score(y_test, predicted))\n","print(\" Recall:\",metrics.recall_score(y_test, predicted))\n","print(\" F1:\",metrics.f1_score(y_test, predicted))\n","\n","\n","confusion_matrix = metrics.confusion_matrix(y_test, predicted)\n","cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['BEFORE', 'AFTER'])\n","cm_display.plot()\n","plt.show()\n","\n","'''\n","with class weights\n","\n","Accuracy: 0.5894021739130435\n","Precision: 0.5689873417721519\n"," Recall: 0.5199537304800462\n"," F1: 0.5433665760048353\n","\n","\n"," without\n","Accuracy: 0.5918478260869565\n","Precision: 0.570804741110418\n"," Recall: 0.5292076344707923\n"," F1: 0.5492196878751501\n","\n"," '''"],"metadata":{"id":"bvo4lE_eSEHf","colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"status":"ok","timestamp":1687389874494,"user_tz":-120,"elapsed":334,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"b04215f7-74d0-4d57-d770-6fc4723aceef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Accuracy: 0.5894021739130435\n","Precision: 0.5689873417721519\n"," Recall: 0.5199537304800462\n"," F1: 0.5433665760048353\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 800x800 with 0 Axes>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["' \\nwith class weights\\n\\nAccuracy: 0.5894021739130435\\nPrecision: 0.5689873417721519\\n Recall: 0.5199537304800462\\n F1: 0.5433665760048353\\n\\n\\n without\\nAccuracy: 0.5918478260869565\\nPrecision: 0.570804741110418\\n Recall: 0.5292076344707923\\n F1: 0.5492196878751501\\n\\n '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","cm = confusion_matrix(y_test, predicted)\n","# Normalise\n","cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","fig, ax = plt.subplots(figsize=(10,10))\n","sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=['BEFORE', \"AFTER\"], yticklabels=['BEFORE', 'AFTER'])\n","\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.show(block=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":850},"id":"PECJpdd0qz0h","executionInfo":{"status":"ok","timestamp":1687388583858,"user_tz":-120,"elapsed":725,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"a43a01c1-7c04-42d3-e6f4-c8e7030cbf74"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x1000 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3qJOLx2zrz8G","executionInfo":{"status":"ok","timestamp":1687386623946,"user_tz":-120,"elapsed":228,"user":{"displayName":"Selin Zobu","userId":"06163236317826837676"}},"outputId":"78dba771-77b0-4430-e05c-46b773232281"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BERT_Arch(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (fc2): Linear(in_features=768, out_features=2, bias=True)\n","  (softmax): LogSoftmax(dim=1)\n",")"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":[],"metadata":{"id":"KTrPe7gGN4El"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fhOKRFWXN4Gk"},"execution_count":null,"outputs":[]}]}